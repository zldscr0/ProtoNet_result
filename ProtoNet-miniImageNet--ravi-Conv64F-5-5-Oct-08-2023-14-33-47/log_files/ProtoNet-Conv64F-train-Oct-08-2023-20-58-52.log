2023-10-08 20:58:55,790 [INFO] core.trainer: {'data_root': '/home/bzx_yjy/FS/miniImageNet--ravi', 'image_size': 84, 'use_memory': False, 'augment': True, 'augment_times': 1, 'augment_times_query': 1, 'workers': 8, 'dataloader_num': 1, 'device_ids': '0,1', 'n_gpu': 2, 'seed': 2147483647, 'deterministic': True, 'port': 30537, 'log_name': None, 'log_level': 'info', 'log_interval': 100, 'log_paramerter': False, 'result_root': './results', 'save_interval': 10, 'save_part': ['emb_func'], 'tag': None, 'epoch': 50, 'test_epoch': 5, 'parallel_part': ['emb_func'], 'pretrain_path': None, 'resume': True, 'way_num': 5, 'shot_num': 5, 'query_num': 15, 'test_way': 5, 'test_shot': 5, 'test_query': 15, 'episode_size': 2, 'train_episode': 10000, 'test_episode': 1000, 'batch_size': 128, 'val_per_epoch': 1, 'optimizer': {'kwargs': {'lr': 0.01}, 'name': 'SGD', 'other': None}, 'lr_scheduler': {'kwargs': {'gamma': 1.0, 'step_size': 20}, 'name': 'StepLR'}, 'warmup': 0, 'includes': ['headers/data.yaml', 'headers/device.yaml', 'headers/misc.yaml', 'headers/model.yaml', 'headers/optimizer.yaml', 'classifiers/Proto.yaml', 'backbones/resnet12.yaml'], 'backbone': {'kwargs': {'is_feature': False, 'is_flatten': True, 'last_pool': True, 'leaky_relu': False, 'negative_slope': 0.2}, 'name': 'Conv64F'}, 'classifier': {'kwargs': None, 'name': 'ProtoNet'}, 'rank': 0, 'tb_scale': 10.0, 'resume_path': './results/ProtoNet-miniImageNet--ravi-Conv64F-5-5-Oct-08-2023-14-33-47'}
2023-10-08 20:58:55,803 [INFO] core.trainer: ProtoNet(
  (emb_func): Conv64F(
    (layer1): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (layer2): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (layer3): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (layer3_maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (layer4): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (layer4_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (proto_layer): ProtoLayer()
  (loss_func): CrossEntropyLoss()
)
2023-10-08 20:58:55,812 [INFO] core.trainer: Trainable params in the model: 113088
2023-10-08 20:58:55,813 [INFO] core.trainer: load the resume model checkpoints dict from ./results/ProtoNet-miniImageNet--ravi-Conv64F-5-5-Oct-08-2023-14-33-47/checkpoints/model_last.pth.
2023-10-08 20:58:55,991 [INFO] core.trainer: load 38400 train image with 64 label.
2023-10-08 20:59:07,531 [INFO] core.trainer: load 9600 val image with 16 label.
2023-10-08 20:59:18,166 [INFO] core.trainer: load 12000 test image with 20 label.
2023-10-08 20:59:29,047 [INFO] core.trainer: SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    initial_lr: 0.01
    lr: 0.01
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
)
2023-10-08 20:59:29,051 [INFO] core.trainer: load the optimizer, lr_scheduler and epoch checkpoints dict from ./results/ProtoNet-miniImageNet--ravi-Conv64F-5-5-Oct-08-2023-14-33-47/checkpoints/model_last.pth.
2023-10-08 20:59:29,157 [INFO] core.trainer: model resume from the epoch 30
2023-10-08 20:59:29,159 [INFO] core.trainer: ============ Train on the train set ============
2023-10-08 20:59:29,160 [INFO] core.trainer: learning rate: [0.01]
2023-10-08 20:59:40,060 [INFO] core.trainer: Epoch-(31): [100/10000]	Time 0.453 (0.217)	Calc 0.069 (0.124)	Data 0.373 (0.078)	Loss 0.674 (0.658)	Acc@1 70.000 (74.600)
2023-10-08 20:59:46,936 [INFO] core.trainer: Epoch-(31): [200/10000]	Time 0.071 (0.177)	Calc 0.051 (0.079)	Data 0.003 (0.084)	Loss 0.954 (0.713)	Acc@1 75.333 (73.027)
2023-10-08 20:59:54,553 [INFO] core.trainer: Epoch-(31): [300/10000]	Time 0.087 (0.168)	Calc 0.063 (0.069)	Data 0.001 (0.086)	Loss 0.735 (0.692)	Acc@1 70.667 (73.529)
2023-10-08 21:00:01,982 [INFO] core.trainer: Epoch-(31): [400/10000]	Time 0.049 (0.163)	Calc 0.039 (0.084)	Data 0.001 (0.066)	Loss 0.668 (0.694)	Acc@1 80.667 (73.310)
2023-10-08 21:00:08,873 [INFO] core.trainer: Epoch-(31): [500/10000]	Time 0.050 (0.158)	Calc 0.031 (0.092)	Data 0.003 (0.053)	Loss 0.675 (0.703)	Acc@1 82.000 (73.157)
2023-10-08 21:00:15,683 [INFO] core.trainer: Epoch-(31): [600/10000]	Time 0.063 (0.154)	Calc 0.049 (0.094)	Data 0.001 (0.047)	Loss 0.486 (0.700)	Acc@1 85.333 (73.096)
2023-10-08 21:00:23,473 [INFO] core.trainer: Epoch-(31): [700/10000]	Time 0.621 (0.154)	Calc 0.604 (0.100)	Data 0.001 (0.041)	Loss 1.110 (0.696)	Acc@1 76.000 (73.213)
2023-10-08 21:00:30,275 [INFO] core.trainer: Epoch-(31): [800/10000]	Time 0.042 (0.152)	Calc 0.035 (0.103)	Data 0.001 (0.036)	Loss 0.607 (0.697)	Acc@1 80.667 (73.285)
2023-10-08 21:00:37,987 [INFO] core.trainer: Epoch-(31): [900/10000]	Time 0.415 (0.152)	Calc 0.399 (0.107)	Data 0.001 (0.033)	Loss 0.611 (0.693)	Acc@1 75.333 (73.428)
2023-10-08 21:00:45,382 [INFO] core.trainer: Epoch-(31): [1000/10000]	Time 0.107 (0.152)	Calc 0.068 (0.109)	Data 0.024 (0.030)	Loss 0.503 (0.692)	Acc@1 68.667 (73.595)
2023-10-08 21:00:52,263 [INFO] core.trainer: Epoch-(31): [1100/10000]	Time 0.081 (0.150)	Calc 0.077 (0.109)	Data 0.002 (0.029)	Loss 0.429 (0.695)	Acc@1 74.000 (73.452)
2023-10-08 21:00:58,912 [INFO] core.trainer: Epoch-(31): [1200/10000]	Time 0.164 (0.149)	Calc 0.017 (0.109)	Data 0.141 (0.027)	Loss 0.633 (0.695)	Acc@1 76.667 (73.363)
2023-10-08 21:01:05,488 [INFO] core.trainer: Epoch-(31): [1300/10000]	Time 0.173 (0.147)	Calc 0.050 (0.105)	Data 0.096 (0.030)	Loss 0.540 (0.697)	Acc@1 68.000 (73.297)
2023-10-08 21:01:12,157 [INFO] core.trainer: Epoch-(31): [1400/10000]	Time 0.022 (0.146)	Calc 0.015 (0.101)	Data 0.001 (0.033)	Loss 0.545 (0.700)	Acc@1 70.000 (73.240)
2023-10-08 21:01:19,493 [INFO] core.trainer: Epoch-(31): [1500/10000]	Time 0.021 (0.146)	Calc 0.014 (0.100)	Data 0.001 (0.033)	Loss 0.647 (0.697)	Acc@1 66.667 (73.257)
2023-10-08 21:01:26,335 [INFO] core.trainer: Epoch-(31): [1600/10000]	Time 0.468 (0.146)	Calc 0.439 (0.099)	Data 0.009 (0.035)	Loss 0.713 (0.695)	Acc@1 78.000 (73.256)
2023-10-08 21:01:34,155 [INFO] core.trainer: Epoch-(31): [1700/10000]	Time 0.079 (0.146)	Calc 0.049 (0.099)	Data 0.004 (0.035)	Loss 0.639 (0.694)	Acc@1 62.667 (73.249)
2023-10-08 21:01:41,227 [INFO] core.trainer: Epoch-(31): [1800/10000]	Time 0.281 (0.146)	Calc 0.274 (0.100)	Data 0.001 (0.033)	Loss 0.826 (0.694)	Acc@1 72.667 (73.368)
2023-10-08 21:01:48,225 [INFO] core.trainer: Epoch-(31): [1900/10000]	Time 0.056 (0.146)	Calc 0.041 (0.100)	Data 0.001 (0.033)	Loss 0.743 (0.694)	Acc@1 72.000 (73.408)
2023-10-08 21:01:55,916 [INFO] core.trainer: Epoch-(31): [2000/10000]	Time 0.050 (0.146)	Calc 0.023 (0.099)	Data 0.001 (0.034)	Loss 0.773 (0.694)	Acc@1 63.333 (73.357)
2023-10-08 21:02:02,815 [INFO] core.trainer: Epoch-(31): [2100/10000]	Time 0.050 (0.146)	Calc 0.046 (0.098)	Data 0.000 (0.035)	Loss 0.504 (0.692)	Acc@1 69.333 (73.448)
2023-10-08 21:02:09,428 [INFO] core.trainer: Epoch-(31): [2200/10000]	Time 0.021 (0.145)	Calc 0.014 (0.096)	Data 0.001 (0.036)	Loss 0.257 (0.691)	Acc@1 81.333 (73.462)
2023-10-08 21:02:16,405 [INFO] core.trainer: Epoch-(31): [2300/10000]	Time 0.085 (0.145)	Calc 0.055 (0.094)	Data 0.001 (0.038)	Loss 0.734 (0.689)	Acc@1 63.333 (73.457)
2023-10-08 21:02:22,896 [INFO] core.trainer: Epoch-(31): [2400/10000]	Time 0.026 (0.144)	Calc 0.019 (0.093)	Data 0.001 (0.038)	Loss 1.062 (0.691)	Acc@1 70.667 (73.476)
2023-10-08 21:02:29,882 [INFO] core.trainer: Epoch-(31): [2500/10000]	Time 0.050 (0.144)	Calc 0.034 (0.094)	Data 0.001 (0.037)	Loss 0.594 (0.692)	Acc@1 70.667 (73.464)
2023-10-08 21:02:37,521 [INFO] core.trainer: Epoch-(31): [2600/10000]	Time 0.058 (0.144)	Calc 0.045 (0.092)	Data 0.001 (0.039)	Loss 0.734 (0.692)	Acc@1 66.667 (73.437)
2023-10-08 21:02:44,587 [INFO] core.trainer: Epoch-(31): [2700/10000]	Time 0.037 (0.144)	Calc 0.030 (0.090)	Data 0.002 (0.041)	Loss 0.439 (0.691)	Acc@1 77.333 (73.419)
2023-10-08 21:02:51,888 [INFO] core.trainer: Epoch-(31): [2800/10000]	Time 0.121 (0.144)	Calc 0.069 (0.090)	Data 0.001 (0.041)	Loss 0.775 (0.692)	Acc@1 72.667 (73.391)
2023-10-08 21:02:58,720 [INFO] core.trainer: Epoch-(31): [2900/10000]	Time 0.092 (0.144)	Calc 0.066 (0.089)	Data 0.001 (0.042)	Loss 0.419 (0.691)	Acc@1 84.667 (73.400)
2023-10-08 21:03:05,936 [INFO] core.trainer: Epoch-(31): [3000/10000]	Time 0.055 (0.144)	Calc 0.044 (0.090)	Data 0.001 (0.041)	Loss 0.816 (0.693)	Acc@1 77.333 (73.340)
2023-10-08 21:03:12,172 [INFO] core.trainer: Epoch-(31): [3100/10000]	Time 0.203 (0.143)	Calc 0.190 (0.089)	Data 0.001 (0.042)	Loss 0.875 (0.692)	Acc@1 72.000 (73.358)
2023-10-08 21:03:19,798 [INFO] core.trainer: Epoch-(31): [3200/10000]	Time 0.406 (0.143)	Calc 0.389 (0.088)	Data 0.001 (0.043)	Loss 0.828 (0.693)	Acc@1 74.000 (73.360)
2023-10-08 21:03:27,029 [INFO] core.trainer: Epoch-(31): [3300/10000]	Time 0.070 (0.143)	Calc 0.054 (0.088)	Data 0.001 (0.042)	Loss 0.695 (0.694)	Acc@1 71.333 (73.366)
2023-10-08 21:03:32,662 [INFO] core.trainer: Epoch-(31): [3400/10000]	Time 0.328 (0.143)	Calc 0.311 (0.088)	Data 0.001 (0.042)	Loss 0.516 (0.693)	Acc@1 80.000 (73.416)
2023-10-08 21:03:40,268 [INFO] core.trainer: Epoch-(31): [3500/10000]	Time 0.023 (0.143)	Calc 0.016 (0.089)	Data 0.001 (0.041)	Loss 0.725 (0.692)	Acc@1 72.000 (73.368)
2023-10-08 21:03:48,578 [INFO] core.trainer: Epoch-(31): [3600/10000]	Time 0.536 (0.143)	Calc 0.474 (0.090)	Data 0.028 (0.040)	Loss 0.623 (0.692)	Acc@1 66.000 (73.327)
2023-10-08 21:03:55,355 [INFO] core.trainer: Epoch-(31): [3700/10000]	Time 0.267 (0.143)	Calc 0.041 (0.091)	Data 0.212 (0.040)	Loss 0.632 (0.692)	Acc@1 71.333 (73.314)
2023-10-08 21:04:02,332 [INFO] core.trainer: Epoch-(31): [3800/10000]	Time 0.339 (0.143)	Calc 0.331 (0.090)	Data 0.001 (0.040)	Loss 0.283 (0.692)	Acc@1 86.667 (73.360)
2023-10-08 21:04:09,256 [INFO] core.trainer: Epoch-(31): [3900/10000]	Time 0.070 (0.143)	Calc 0.049 (0.089)	Data 0.008 (0.041)	Loss 0.720 (0.691)	Acc@1 63.333 (73.364)
2023-10-08 21:04:16,040 [INFO] core.trainer: Epoch-(31): [4000/10000]	Time 0.023 (0.143)	Calc 0.017 (0.089)	Data 0.001 (0.041)	Loss 0.380 (0.690)	Acc@1 86.667 (73.398)
2023-10-08 21:04:23,981 [INFO] core.trainer: Epoch-(31): [4100/10000]	Time 0.245 (0.143)	Calc 0.016 (0.090)	Data 0.219 (0.041)	Loss 0.690 (0.690)	Acc@1 72.000 (73.408)
2023-10-08 21:04:31,019 [INFO] core.trainer: Epoch-(31): [4200/10000]	Time 0.034 (0.143)	Calc 0.026 (0.089)	Data 0.002 (0.042)	Loss 1.006 (0.690)	Acc@1 60.667 (73.424)
2023-10-08 21:04:37,004 [INFO] core.trainer: Epoch-(31): [4300/10000]	Time 0.046 (0.142)	Calc 0.029 (0.087)	Data 0.001 (0.042)	Loss 0.725 (0.690)	Acc@1 60.667 (73.404)
2023-10-08 21:04:45,045 [INFO] core.trainer: Epoch-(31): [4400/10000]	Time 0.381 (0.143)	Calc 0.017 (0.088)	Data 0.358 (0.042)	Loss 0.629 (0.689)	Acc@1 65.333 (73.427)
2023-10-08 21:04:52,206 [INFO] core.trainer: Epoch-(31): [4500/10000]	Time 0.066 (0.143)	Calc 0.051 (0.087)	Data 0.001 (0.043)	Loss 0.692 (0.689)	Acc@1 70.000 (73.408)
2023-10-08 21:04:58,464 [INFO] core.trainer: Epoch-(31): [4600/10000]	Time 0.282 (0.142)	Calc 0.273 (0.086)	Data 0.001 (0.043)	Loss 0.535 (0.689)	Acc@1 70.000 (73.429)
2023-10-08 21:05:05,791 [INFO] core.trainer: Epoch-(31): [4700/10000]	Time 0.035 (0.143)	Calc 0.017 (0.087)	Data 0.001 (0.043)	Loss 0.518 (0.688)	Acc@1 82.000 (73.439)
2023-10-08 21:05:12,697 [INFO] core.trainer: Epoch-(31): [4800/10000]	Time 0.048 (0.142)	Calc 0.041 (0.086)	Data 0.001 (0.044)	Loss 0.693 (0.688)	Acc@1 76.000 (73.450)
2023-10-08 21:05:20,242 [INFO] core.trainer: Epoch-(31): [4900/10000]	Time 0.323 (0.143)	Calc 0.197 (0.085)	Data 0.120 (0.045)	Loss 0.606 (0.688)	Acc@1 82.667 (73.475)
2023-10-08 21:05:27,277 [INFO] core.trainer: Epoch-(31): [5000/10000]	Time 0.091 (0.143)	Calc 0.084 (0.084)	Data 0.001 (0.046)	Loss 0.799 (0.689)	Acc@1 75.333 (73.455)
2023-10-08 21:05:34,649 [INFO] core.trainer: Epoch-(31): [5100/10000]	Time 0.058 (0.143)	Calc 0.038 (0.085)	Data 0.001 (0.045)	Loss 0.711 (0.688)	Acc@1 72.667 (73.475)
2023-10-08 21:05:41,235 [INFO] core.trainer: Epoch-(31): [5200/10000]	Time 0.028 (0.142)	Calc 0.021 (0.084)	Data 0.001 (0.045)	Loss 0.569 (0.689)	Acc@1 70.667 (73.475)
2023-10-08 21:05:48,121 [INFO] core.trainer: Epoch-(31): [5300/10000]	Time 0.036 (0.142)	Calc 0.020 (0.084)	Data 0.001 (0.046)	Loss 0.912 (0.688)	Acc@1 68.000 (73.488)
2023-10-08 21:05:56,221 [INFO] core.trainer: Epoch-(31): [5400/10000]	Time 0.363 (0.143)	Calc 0.354 (0.085)	Data 0.001 (0.045)	Loss 0.707 (0.689)	Acc@1 71.333 (73.460)
2023-10-08 21:06:02,413 [INFO] core.trainer: Epoch-(31): [5500/10000]	Time 0.051 (0.142)	Calc 0.033 (0.085)	Data 0.002 (0.045)	Loss 0.718 (0.689)	Acc@1 72.667 (73.440)
2023-10-08 21:06:09,182 [INFO] core.trainer: Epoch-(31): [5600/10000]	Time 0.105 (0.142)	Calc 0.099 (0.084)	Data 0.002 (0.045)	Loss 0.800 (0.690)	Acc@1 76.667 (73.408)
2023-10-08 21:06:16,745 [INFO] core.trainer: Epoch-(31): [5700/10000]	Time 0.075 (0.142)	Calc 0.052 (0.084)	Data 0.001 (0.045)	Loss 0.519 (0.688)	Acc@1 80.667 (73.458)
2023-10-08 21:06:22,625 [INFO] core.trainer: Epoch-(31): [5800/10000]	Time 0.035 (0.142)	Calc 0.026 (0.084)	Data 0.001 (0.046)	Loss 0.914 (0.688)	Acc@1 61.333 (73.468)
2023-10-08 21:06:30,499 [INFO] core.trainer: Epoch-(31): [5900/10000]	Time 0.150 (0.142)	Calc 0.078 (0.083)	Data 0.056 (0.047)	Loss 0.714 (0.688)	Acc@1 76.000 (73.462)
2023-10-08 21:06:37,280 [INFO] core.trainer: Epoch-(31): [6000/10000]	Time 0.330 (0.142)	Calc 0.046 (0.083)	Data 0.265 (0.047)	Loss 0.691 (0.688)	Acc@1 60.000 (73.471)
2023-10-08 21:06:44,616 [INFO] core.trainer: Epoch-(31): [6100/10000]	Time 0.072 (0.142)	Calc 0.050 (0.083)	Data 0.001 (0.047)	Loss 0.701 (0.688)	Acc@1 76.000 (73.474)
2023-10-08 21:06:51,828 [INFO] core.trainer: Epoch-(31): [6200/10000]	Time 0.086 (0.142)	Calc 0.066 (0.083)	Data 0.000 (0.046)	Loss 0.950 (0.689)	Acc@1 68.000 (73.481)
2023-10-08 21:06:58,676 [INFO] core.trainer: Epoch-(31): [6300/10000]	Time 0.030 (0.142)	Calc 0.015 (0.084)	Data 0.001 (0.046)	Loss 0.323 (0.688)	Acc@1 81.333 (73.486)
2023-10-08 21:07:06,193 [INFO] core.trainer: Epoch-(31): [6400/10000]	Time 0.214 (0.142)	Calc 0.045 (0.084)	Data 0.151 (0.046)	Loss 0.841 (0.688)	Acc@1 73.333 (73.485)
2023-10-08 21:07:13,017 [INFO] core.trainer: Epoch-(31): [6500/10000]	Time 0.162 (0.142)	Calc 0.044 (0.083)	Data 0.114 (0.046)	Loss 0.898 (0.688)	Acc@1 58.667 (73.467)
2023-10-08 21:07:20,314 [INFO] core.trainer: Epoch-(31): [6600/10000]	Time 0.201 (0.142)	Calc 0.016 (0.083)	Data 0.179 (0.047)	Loss 0.844 (0.689)	Acc@1 70.000 (73.438)
2023-10-08 21:07:25,755 [INFO] core.trainer: Epoch-(31): [6700/10000]	Time 0.033 (0.142)	Calc 0.015 (0.082)	Data 0.001 (0.047)	Loss 0.760 (0.689)	Acc@1 74.000 (73.424)
2023-10-08 21:07:34,320 [INFO] core.trainer: Epoch-(31): [6800/10000]	Time 0.243 (0.142)	Calc 0.233 (0.081)	Data 0.001 (0.048)	Loss 0.866 (0.691)	Acc@1 64.667 (73.381)
2023-10-08 21:07:41,147 [INFO] core.trainer: Epoch-(31): [6900/10000]	Time 0.038 (0.142)	Calc 0.018 (0.082)	Data 0.001 (0.047)	Loss 0.294 (0.691)	Acc@1 88.000 (73.364)
2023-10-08 21:07:47,656 [INFO] core.trainer: Epoch-(31): [7000/10000]	Time 0.057 (0.142)	Calc 0.042 (0.082)	Data 0.001 (0.047)	Loss 0.397 (0.691)	Acc@1 84.667 (73.367)
2023-10-08 21:07:54,635 [INFO] core.trainer: Epoch-(31): [7100/10000]	Time 0.124 (0.142)	Calc 0.096 (0.082)	Data 0.001 (0.047)	Loss 1.075 (0.690)	Acc@1 56.667 (73.392)
2023-10-08 21:08:01,246 [INFO] core.trainer: Epoch-(31): [7200/10000]	Time 0.047 (0.142)	Calc 0.029 (0.082)	Data 0.001 (0.047)	Loss 1.237 (0.690)	Acc@1 62.000 (73.397)
2023-10-08 21:08:08,335 [INFO] core.trainer: Epoch-(31): [7300/10000]	Time 0.024 (0.142)	Calc 0.014 (0.083)	Data 0.001 (0.046)	Loss 0.669 (0.689)	Acc@1 66.667 (73.426)
2023-10-08 21:08:14,727 [INFO] core.trainer: Epoch-(31): [7400/10000]	Time 0.087 (0.141)	Calc 0.065 (0.083)	Data 0.004 (0.046)	Loss 0.640 (0.689)	Acc@1 77.333 (73.427)
2023-10-08 21:08:22,706 [INFO] core.trainer: Epoch-(31): [7500/10000]	Time 0.639 (0.142)	Calc 0.034 (0.082)	Data 0.598 (0.047)	Loss 0.605 (0.689)	Acc@1 74.667 (73.443)
2023-10-08 21:08:28,732 [INFO] core.trainer: Epoch-(31): [7600/10000]	Time 0.035 (0.141)	Calc 0.028 (0.082)	Data 0.001 (0.047)	Loss 0.527 (0.689)	Acc@1 73.333 (73.444)
2023-10-08 21:08:36,191 [INFO] core.trainer: Epoch-(31): [7700/10000]	Time 0.059 (0.141)	Calc 0.039 (0.081)	Data 0.000 (0.048)	Loss 0.899 (0.690)	Acc@1 65.333 (73.425)
2023-10-08 21:08:43,596 [INFO] core.trainer: Epoch-(31): [7800/10000]	Time 0.064 (0.141)	Calc 0.050 (0.081)	Data 0.001 (0.048)	Loss 0.518 (0.690)	Acc@1 74.667 (73.403)
2023-10-08 21:08:50,352 [INFO] core.trainer: Epoch-(31): [7900/10000]	Time 0.046 (0.141)	Calc 0.031 (0.080)	Data 0.001 (0.048)	Loss 0.296 (0.690)	Acc@1 84.667 (73.397)
2023-10-08 21:08:57,715 [INFO] core.trainer: Epoch-(31): [8000/10000]	Time 0.072 (0.141)	Calc 0.046 (0.080)	Data 0.006 (0.048)	Loss 0.941 (0.690)	Acc@1 70.000 (73.396)
2023-10-08 21:09:04,431 [INFO] core.trainer: Epoch-(31): [8100/10000]	Time 0.028 (0.141)	Calc 0.020 (0.080)	Data 0.002 (0.049)	Loss 0.701 (0.690)	Acc@1 78.667 (73.397)
2023-10-08 21:09:10,906 [INFO] core.trainer: Epoch-(31): [8200/10000]	Time 0.335 (0.141)	Calc 0.031 (0.080)	Data 0.299 (0.049)	Loss 1.014 (0.690)	Acc@1 66.000 (73.404)
2023-10-08 21:09:18,960 [INFO] core.trainer: Epoch-(31): [8300/10000]	Time 0.076 (0.141)	Calc 0.053 (0.080)	Data 0.002 (0.049)	Loss 0.545 (0.690)	Acc@1 82.000 (73.389)
2023-10-08 21:09:26,680 [INFO] core.trainer: Epoch-(31): [8400/10000]	Time 0.076 (0.142)	Calc 0.063 (0.079)	Data 0.000 (0.050)	Loss 0.534 (0.690)	Acc@1 75.333 (73.396)
2023-10-08 21:09:33,423 [INFO] core.trainer: Epoch-(31): [8500/10000]	Time 0.216 (0.141)	Calc 0.187 (0.080)	Data 0.000 (0.049)	Loss 0.789 (0.690)	Acc@1 75.333 (73.405)
2023-10-08 21:09:40,459 [INFO] core.trainer: Epoch-(31): [8600/10000]	Time 0.027 (0.141)	Calc 0.019 (0.080)	Data 0.001 (0.049)	Loss 0.394 (0.690)	Acc@1 68.000 (73.393)
2023-10-08 21:09:47,006 [INFO] core.trainer: Epoch-(31): [8700/10000]	Time 0.044 (0.141)	Calc 0.035 (0.079)	Data 0.001 (0.049)	Loss 0.998 (0.689)	Acc@1 63.333 (73.417)
2023-10-08 21:09:54,560 [INFO] core.trainer: Epoch-(31): [8800/10000]	Time 0.076 (0.141)	Calc 0.048 (0.079)	Data 0.001 (0.050)	Loss 0.790 (0.690)	Acc@1 68.667 (73.417)
2023-10-08 21:10:02,156 [INFO] core.trainer: Epoch-(31): [8900/10000]	Time 0.575 (0.142)	Calc 0.556 (0.079)	Data 0.001 (0.050)	Loss 0.638 (0.690)	Acc@1 69.333 (73.393)
2023-10-08 21:10:08,110 [INFO] core.trainer: Epoch-(31): [9000/10000]	Time 0.023 (0.141)	Calc 0.016 (0.079)	Data 0.001 (0.050)	Loss 0.492 (0.690)	Acc@1 75.333 (73.395)
2023-10-08 21:10:15,535 [INFO] core.trainer: Epoch-(31): [9100/10000]	Time 0.071 (0.141)	Calc 0.052 (0.080)	Data 0.001 (0.049)	Loss 0.546 (0.690)	Acc@1 80.000 (73.425)
2023-10-08 21:10:22,860 [INFO] core.trainer: Epoch-(31): [9200/10000]	Time 0.281 (0.141)	Calc 0.260 (0.080)	Data 0.003 (0.049)	Loss 0.360 (0.690)	Acc@1 88.667 (73.419)
2023-10-08 21:10:29,330 [INFO] core.trainer: Epoch-(31): [9300/10000]	Time 0.266 (0.141)	Calc 0.242 (0.080)	Data 0.001 (0.048)	Loss 0.669 (0.690)	Acc@1 74.667 (73.428)
2023-10-08 21:10:36,544 [INFO] core.trainer: Epoch-(31): [9400/10000]	Time 0.025 (0.141)	Calc 0.017 (0.081)	Data 0.001 (0.048)	Loss 0.648 (0.690)	Acc@1 73.333 (73.424)
2023-10-08 21:10:43,856 [INFO] core.trainer: Epoch-(31): [9500/10000]	Time 0.023 (0.141)	Calc 0.016 (0.081)	Data 0.001 (0.048)	Loss 0.759 (0.690)	Acc@1 74.667 (73.418)
2023-10-08 21:10:50,844 [INFO] core.trainer: Epoch-(31): [9600/10000]	Time 0.118 (0.141)	Calc 0.046 (0.080)	Data 0.058 (0.049)	Loss 0.447 (0.690)	Acc@1 84.000 (73.433)
2023-10-08 21:10:57,885 [INFO] core.trainer: Epoch-(31): [9700/10000]	Time 0.046 (0.141)	Calc 0.027 (0.080)	Data 0.015 (0.049)	Loss 0.574 (0.690)	Acc@1 74.667 (73.446)
2023-10-08 21:11:04,790 [INFO] core.trainer: Epoch-(31): [9800/10000]	Time 0.023 (0.141)	Calc 0.016 (0.080)	Data 0.001 (0.049)	Loss 0.640 (0.689)	Acc@1 67.333 (73.445)
2023-10-08 21:11:11,870 [INFO] core.trainer: Epoch-(31): [9900/10000]	Time 0.028 (0.141)	Calc 0.022 (0.080)	Data 0.001 (0.048)	Loss 0.720 (0.690)	Acc@1 70.667 (73.445)
2023-10-08 21:11:19,193 [INFO] core.trainer: Epoch-(31): [10000/10000]	Time 0.549 (0.141)	Calc 0.015 (0.080)	Data 0.528 (0.048)	Loss 0.646 (0.690)	Acc@1 78.000 (73.457)
2023-10-08 21:11:19,205 [INFO] core.trainer:  * Acc@1 73.457 
2023-10-08 21:11:19,207 [INFO] core.trainer: ============ Validation on the val set ============
2023-10-08 21:11:25,618 [INFO] core.trainer: Epoch-(31): [100/1000]	Time 0.011 (0.128)	Calc 0.007 (0.046)	Data 0.001 (0.078)	Acc@1 72.000 (64.533)
2023-10-08 21:11:32,402 [INFO] core.trainer: Epoch-(31): [200/1000]	Time 0.018 (0.131)	Calc 0.014 (0.086)	Data 0.001 (0.043)	Acc@1 70.000 (65.000)
2023-10-08 21:11:38,906 [INFO] core.trainer: Epoch-(31): [300/1000]	Time 0.157 (0.131)	Calc 0.006 (0.072)	Data 0.149 (0.056)	Acc@1 72.667 (65.076)
2023-10-08 21:11:46,054 [INFO] core.trainer: Epoch-(31): [400/1000]	Time 0.369 (0.133)	Calc 0.014 (0.060)	Data 0.351 (0.071)	Acc@1 63.333 (64.867)
2023-10-08 21:11:52,974 [INFO] core.trainer: Epoch-(31): [500/1000]	Time 0.009 (0.134)	Calc 0.007 (0.051)	Data 0.000 (0.080)	Acc@1 60.667 (64.781)
2023-10-08 21:11:57,735 [INFO] core.trainer: Epoch-(31): [600/1000]	Time 0.015 (0.128)	Calc 0.013 (0.044)	Data 0.001 (0.081)	Acc@1 74.000 (64.902)
2023-10-08 21:12:03,838 [INFO] core.trainer: Epoch-(31): [700/1000]	Time 0.017 (0.127)	Calc 0.008 (0.040)	Data 0.008 (0.084)	Acc@1 75.333 (65.032)
2023-10-08 21:12:10,130 [INFO] core.trainer: Epoch-(31): [800/1000]	Time 0.262 (0.126)	Calc 0.029 (0.039)	Data 0.230 (0.084)	Acc@1 72.000 (65.138)
2023-10-08 21:12:16,028 [INFO] core.trainer: Epoch-(31): [900/1000]	Time 0.010 (0.125)	Calc 0.007 (0.039)	Data 0.001 (0.084)	Acc@1 74.667 (65.247)
2023-10-08 21:12:22,874 [INFO] core.trainer: Epoch-(31): [1000/1000]	Time 0.228 (0.127)	Calc 0.224 (0.037)	Data 0.001 (0.086)	Acc@1 66.000 (65.213)
2023-10-08 21:12:22,880 [INFO] core.trainer:  * Acc@1 65.213 Best acc 66.428
2023-10-08 21:12:22,882 [INFO] core.trainer: ============ Testing on the test set ============
2023-10-08 21:12:29,001 [INFO] core.trainer: Epoch-(31): [100/1000]	Time 0.018 (0.122)	Calc 0.012 (0.076)	Data 0.003 (0.042)	Acc@1 72.000 (63.613)
2023-10-08 21:12:34,757 [INFO] core.trainer: Epoch-(31): [200/1000]	Time 0.445 (0.118)	Calc 0.441 (0.092)	Data 0.001 (0.024)	Acc@1 67.333 (63.813)
2023-10-08 21:12:40,225 [INFO] core.trainer: Epoch-(31): [300/1000]	Time 0.010 (0.115)	Calc 0.006 (0.088)	Data 0.001 (0.025)	Acc@1 66.667 (63.822)
2023-10-08 21:12:46,980 [INFO] core.trainer: Epoch-(31): [400/1000]	Time 0.524 (0.120)	Calc 0.521 (0.097)	Data 0.001 (0.020)	Acc@1 74.667 (64.043)
2023-10-08 21:12:53,541 [INFO] core.trainer: Epoch-(31): [500/1000]	Time 0.327 (0.122)	Calc 0.320 (0.100)	Data 0.005 (0.019)	Acc@1 64.667 (63.931)
2023-10-08 21:12:59,961 [INFO] core.trainer: Epoch-(31): [600/1000]	Time 0.010 (0.123)	Calc 0.007 (0.104)	Data 0.001 (0.017)	Acc@1 50.667 (64.358)
2023-10-08 21:13:04,983 [INFO] core.trainer: Epoch-(31): [700/1000]	Time 0.393 (0.120)	Calc 0.388 (0.103)	Data 0.001 (0.014)	Acc@1 70.667 (64.410)
2023-10-08 21:13:11,407 [INFO] core.trainer: Epoch-(31): [800/1000]	Time 0.025 (0.121)	Calc 0.022 (0.098)	Data 0.001 (0.020)	Acc@1 64.000 (64.465)
2023-10-08 21:13:17,284 [INFO] core.trainer: Epoch-(31): [900/1000]	Time 0.012 (0.120)	Calc 0.010 (0.091)	Data 0.001 (0.026)	Acc@1 60.000 (64.456)
2023-10-08 21:13:23,851 [INFO] core.trainer: Epoch-(31): [1000/1000]	Time 0.011 (0.121)	Calc 0.008 (0.089)	Data 0.001 (0.030)	Acc@1 66.667 (64.540)
2023-10-08 21:13:23,854 [INFO] core.trainer:  * Acc@1 64.540 Best acc 66.428
2023-10-08 21:13:23,856 [INFO] core.trainer:  * Time: 0:13:54/4:24:06
2023-10-08 21:13:23,864 [INFO] core.trainer: ============ Train on the train set ============
2023-10-08 21:13:23,866 [INFO] core.trainer: learning rate: [0.01]
2023-10-08 21:13:29,399 [INFO] core.trainer: Epoch-(32): [100/10000]	Time 0.023 (0.110)	Calc 0.017 (0.046)	Data 0.001 (0.054)	Loss 0.790 (0.685)	Acc@1 79.333 (74.027)
2023-10-08 21:13:37,323 [INFO] core.trainer: Epoch-(32): [200/10000]	Time 0.075 (0.134)	Calc 0.059 (0.061)	Data 0.001 (0.061)	Loss 0.670 (0.680)	Acc@1 74.667 (73.860)
2023-10-08 21:13:44,477 [INFO] core.trainer: Epoch-(32): [300/10000]	Time 0.022 (0.137)	Calc 0.016 (0.060)	Data 0.000 (0.065)	Loss 0.713 (0.682)	Acc@1 68.000 (73.680)
2023-10-08 21:13:50,966 [INFO] core.trainer: Epoch-(32): [400/10000]	Time 0.420 (0.135)	Calc 0.075 (0.071)	Data 0.339 (0.052)	Loss 0.535 (0.693)	Acc@1 82.000 (73.193)
2023-10-08 21:13:58,053 [INFO] core.trainer: Epoch-(32): [500/10000]	Time 0.112 (0.136)	Calc 0.097 (0.080)	Data 0.008 (0.044)	Loss 0.746 (0.693)	Acc@1 72.667 (73.216)
2023-10-08 21:14:04,297 [INFO] core.trainer: Epoch-(32): [600/10000]	Time 0.022 (0.134)	Calc 0.014 (0.085)	Data 0.000 (0.037)	Loss 0.635 (0.698)	Acc@1 75.333 (73.109)
2023-10-08 21:14:11,046 [INFO] core.trainer: Epoch-(32): [700/10000]	Time 0.071 (0.134)	Calc 0.061 (0.083)	Data 0.001 (0.038)	Loss 0.401 (0.693)	Acc@1 74.667 (73.408)
2023-10-08 21:14:18,607 [INFO] core.trainer: Epoch-(32): [800/10000]	Time 0.381 (0.136)	Calc 0.015 (0.077)	Data 0.360 (0.046)	Loss 0.930 (0.695)	Acc@1 73.333 (73.375)
2023-10-08 21:14:25,509 [INFO] core.trainer: Epoch-(32): [900/10000]	Time 0.218 (0.136)	Calc 0.208 (0.075)	Data 0.001 (0.048)	Loss 0.717 (0.697)	Acc@1 77.333 (73.279)
2023-10-08 21:14:31,717 [INFO] core.trainer: Epoch-(32): [1000/10000]	Time 0.067 (0.135)	Calc 0.049 (0.073)	Data 0.001 (0.050)	Loss 0.712 (0.697)	Acc@1 70.000 (73.257)
2023-10-08 21:14:39,004 [INFO] core.trainer: Epoch-(32): [1100/10000]	Time 0.076 (0.136)	Calc 0.053 (0.070)	Data 0.001 (0.054)	Loss 0.634 (0.697)	Acc@1 67.333 (73.267)
2023-10-08 21:14:45,673 [INFO] core.trainer: Epoch-(32): [1200/10000]	Time 0.121 (0.136)	Calc 0.070 (0.067)	Data 0.001 (0.056)	Loss 0.822 (0.698)	Acc@1 81.333 (73.390)
2023-10-08 21:14:52,356 [INFO] core.trainer: Epoch-(32): [1300/10000]	Time 0.210 (0.135)	Calc 0.018 (0.069)	Data 0.185 (0.054)	Loss 0.556 (0.697)	Acc@1 72.000 (73.414)
2023-10-08 21:14:59,028 [INFO] core.trainer: Epoch-(32): [1400/10000]	Time 0.114 (0.135)	Calc 0.084 (0.067)	Data 0.005 (0.055)	Loss 0.539 (0.697)	Acc@1 76.667 (73.414)
2023-10-08 21:15:05,869 [INFO] core.trainer: Epoch-(32): [1500/10000]	Time 0.112 (0.135)	Calc 0.095 (0.068)	Data 0.001 (0.055)	Loss 1.048 (0.698)	Acc@1 70.667 (73.380)
2023-10-08 21:15:12,551 [INFO] core.trainer: Epoch-(32): [1600/10000]	Time 0.044 (0.135)	Calc 0.034 (0.071)	Data 0.001 (0.052)	Loss 0.987 (0.701)	Acc@1 71.333 (73.328)
2023-10-08 21:15:19,625 [INFO] core.trainer: Epoch-(32): [1700/10000]	Time 0.052 (0.136)	Calc 0.037 (0.074)	Data 0.001 (0.049)	Loss 0.654 (0.698)	Acc@1 68.000 (73.357)
2023-10-08 21:15:27,098 [INFO] core.trainer: Epoch-(32): [1800/10000]	Time 0.057 (0.136)	Calc 0.049 (0.077)	Data 0.001 (0.046)	Loss 0.639 (0.698)	Acc@1 78.000 (73.361)
2023-10-08 21:15:33,895 [INFO] core.trainer: Epoch-(32): [1900/10000]	Time 0.267 (0.136)	Calc 0.020 (0.075)	Data 0.240 (0.048)	Loss 0.613 (0.698)	Acc@1 60.000 (73.380)
2023-10-08 21:15:40,860 [INFO] core.trainer: Epoch-(32): [2000/10000]	Time 0.024 (0.136)	Calc 0.016 (0.074)	Data 0.001 (0.050)	Loss 0.593 (0.696)	Acc@1 75.333 (73.423)
2023-10-08 21:15:48,034 [INFO] core.trainer: Epoch-(32): [2100/10000]	Time 0.027 (0.137)	Calc 0.018 (0.073)	Data 0.001 (0.051)	Loss 0.654 (0.697)	Acc@1 73.333 (73.362)
2023-10-08 21:15:54,754 [INFO] core.trainer: Epoch-(32): [2200/10000]	Time 0.021 (0.137)	Calc 0.018 (0.073)	Data 0.001 (0.050)	Loss 0.929 (0.697)	Acc@1 67.333 (73.341)
2023-10-08 21:16:01,888 [INFO] core.trainer: Epoch-(32): [2300/10000]	Time 0.036 (0.137)	Calc 0.016 (0.075)	Data 0.001 (0.049)	Loss 0.550 (0.695)	Acc@1 76.000 (73.367)
2023-10-08 21:16:09,973 [INFO] core.trainer: Epoch-(32): [2400/10000]	Time 0.062 (0.138)	Calc 0.043 (0.076)	Data 0.001 (0.049)	Loss 1.010 (0.697)	Acc@1 66.000 (73.379)
2023-10-08 21:16:16,292 [INFO] core.trainer: Epoch-(32): [2500/10000]	Time 0.067 (0.137)	Calc 0.048 (0.076)	Data 0.001 (0.048)	Loss 0.357 (0.697)	Acc@1 84.667 (73.377)
2023-10-08 21:16:23,530 [INFO] core.trainer: Epoch-(32): [2600/10000]	Time 0.257 (0.138)	Calc 0.237 (0.077)	Data 0.003 (0.048)	Loss 0.874 (0.697)	Acc@1 58.667 (73.385)
2023-10-08 21:16:30,815 [INFO] core.trainer: Epoch-(32): [2700/10000]	Time 0.021 (0.138)	Calc 0.014 (0.077)	Data 0.000 (0.048)	Loss 1.266 (0.698)	Acc@1 62.667 (73.373)
2023-10-08 21:16:37,981 [INFO] core.trainer: Epoch-(32): [2800/10000]	Time 0.025 (0.138)	Calc 0.017 (0.079)	Data 0.001 (0.046)	Loss 0.654 (0.697)	Acc@1 70.667 (73.421)
2023-10-08 21:16:45,599 [INFO] core.trainer: Epoch-(32): [2900/10000]	Time 0.085 (0.138)	Calc 0.065 (0.079)	Data 0.001 (0.047)	Loss 1.096 (0.698)	Acc@1 72.667 (73.377)
2023-10-08 21:16:52,420 [INFO] core.trainer: Epoch-(32): [3000/10000]	Time 0.086 (0.138)	Calc 0.075 (0.078)	Data 0.002 (0.048)	Loss 0.516 (0.697)	Acc@1 81.333 (73.430)
2023-10-08 21:16:58,291 [INFO] core.trainer: Epoch-(32): [3100/10000]	Time 0.263 (0.138)	Calc 0.036 (0.077)	Data 0.217 (0.048)	Loss 0.677 (0.697)	Acc@1 75.333 (73.413)
2023-10-08 21:17:05,623 [INFO] core.trainer: Epoch-(32): [3200/10000]	Time 0.061 (0.138)	Calc 0.054 (0.077)	Data 0.000 (0.049)	Loss 0.858 (0.697)	Acc@1 74.667 (73.381)
2023-10-08 21:17:12,688 [INFO] core.trainer: Epoch-(32): [3300/10000]	Time 0.069 (0.138)	Calc 0.052 (0.078)	Data 0.001 (0.047)	Loss 0.752 (0.696)	Acc@1 78.667 (73.389)
2023-10-08 21:17:19,234 [INFO] core.trainer: Epoch-(32): [3400/10000]	Time 0.032 (0.138)	Calc 0.021 (0.077)	Data 0.002 (0.048)	Loss 0.641 (0.696)	Acc@1 78.000 (73.393)
2023-10-08 21:17:26,327 [INFO] core.trainer: Epoch-(32): [3500/10000]	Time 0.032 (0.138)	Calc 0.024 (0.076)	Data 0.001 (0.049)	Loss 0.657 (0.697)	Acc@1 78.000 (73.359)
2023-10-08 21:17:33,729 [INFO] core.trainer: Epoch-(32): [3600/10000]	Time 0.030 (0.138)	Calc 0.022 (0.076)	Data 0.001 (0.049)	Loss 1.062 (0.698)	Acc@1 66.000 (73.367)
2023-10-08 21:17:40,732 [INFO] core.trainer: Epoch-(32): [3700/10000]	Time 0.034 (0.138)	Calc 0.027 (0.076)	Data 0.002 (0.049)	Loss 0.700 (0.699)	Acc@1 80.000 (73.386)
2023-10-08 21:17:46,482 [INFO] core.trainer: Epoch-(32): [3800/10000]	Time 0.474 (0.138)	Calc 0.052 (0.075)	Data 0.403 (0.050)	Loss 0.685 (0.699)	Acc@1 77.333 (73.393)
2023-10-08 21:17:53,574 [INFO] core.trainer: Epoch-(32): [3900/10000]	Time 0.069 (0.138)	Calc 0.019 (0.074)	Data 0.043 (0.051)	Loss 0.778 (0.700)	Acc@1 74.667 (73.398)
2023-10-08 21:18:00,411 [INFO] core.trainer: Epoch-(32): [4000/10000]	Time 0.090 (0.138)	Calc 0.074 (0.075)	Data 0.001 (0.050)	Loss 0.804 (0.700)	Acc@1 59.333 (73.391)
2023-10-08 21:18:06,540 [INFO] core.trainer: Epoch-(32): [4100/10000]	Time 0.034 (0.137)	Calc 0.020 (0.074)	Data 0.006 (0.051)	Loss 0.343 (0.699)	Acc@1 79.333 (73.419)
2023-10-08 21:18:14,137 [INFO] core.trainer: Epoch-(32): [4200/10000]	Time 0.071 (0.138)	Calc 0.063 (0.074)	Data 0.001 (0.051)	Loss 0.713 (0.698)	Acc@1 78.000 (73.438)
2023-10-08 21:18:21,040 [INFO] core.trainer: Epoch-(32): [4300/10000]	Time 0.206 (0.138)	Calc 0.142 (0.074)	Data 0.059 (0.050)	Loss 0.696 (0.699)	Acc@1 71.333 (73.392)
2023-10-08 21:18:27,618 [INFO] core.trainer: Epoch-(32): [4400/10000]	Time 0.213 (0.137)	Calc 0.023 (0.074)	Data 0.186 (0.051)	Loss 0.787 (0.700)	Acc@1 64.000 (73.407)
2023-10-08 21:18:35,060 [INFO] core.trainer: Epoch-(32): [4500/10000]	Time 0.112 (0.138)	Calc 0.077 (0.073)	Data 0.009 (0.052)	Loss 0.418 (0.700)	Acc@1 79.333 (73.400)
2023-10-08 21:18:42,402 [INFO] core.trainer: Epoch-(32): [4600/10000]	Time 0.055 (0.138)	Calc 0.040 (0.073)	Data 0.001 (0.053)	Loss 0.401 (0.699)	Acc@1 84.667 (73.412)
2023-10-08 21:18:48,908 [INFO] core.trainer: Epoch-(32): [4700/10000]	Time 0.023 (0.138)	Calc 0.016 (0.072)	Data 0.001 (0.053)	Loss 0.391 (0.699)	Acc@1 74.000 (73.434)
2023-10-08 21:18:55,880 [INFO] core.trainer: Epoch-(32): [4800/10000]	Time 0.022 (0.138)	Calc 0.015 (0.072)	Data 0.001 (0.053)	Loss 0.894 (0.698)	Acc@1 71.333 (73.440)
2023-10-08 21:19:03,080 [INFO] core.trainer: Epoch-(32): [4900/10000]	Time 0.089 (0.138)	Calc 0.083 (0.073)	Data 0.001 (0.052)	Loss 0.774 (0.698)	Acc@1 66.667 (73.435)
2023-10-08 21:19:10,113 [INFO] core.trainer: Epoch-(32): [5000/10000]	Time 0.236 (0.138)	Calc 0.221 (0.074)	Data 0.001 (0.051)	Loss 0.984 (0.698)	Acc@1 70.667 (73.417)
2023-10-08 21:19:16,576 [INFO] core.trainer: Epoch-(32): [5100/10000]	Time 0.348 (0.138)	Calc 0.341 (0.074)	Data 0.001 (0.051)	Loss 0.504 (0.697)	Acc@1 80.000 (73.439)
2023-10-08 21:19:23,512 [INFO] core.trainer: Epoch-(32): [5200/10000]	Time 0.131 (0.138)	Calc 0.124 (0.075)	Data 0.001 (0.050)	Loss 0.606 (0.698)	Acc@1 72.667 (73.425)
2023-10-08 21:19:30,562 [INFO] core.trainer: Epoch-(32): [5300/10000]	Time 0.038 (0.138)	Calc 0.031 (0.076)	Data 0.001 (0.049)	Loss 1.017 (0.697)	Acc@1 63.333 (73.407)
2023-10-08 21:19:36,116 [INFO] core.trainer: Epoch-(32): [5400/10000]	Time 0.070 (0.137)	Calc 0.046 (0.076)	Data 0.003 (0.048)	Loss 0.972 (0.697)	Acc@1 72.000 (73.406)
2023-10-08 21:19:44,176 [INFO] core.trainer: Epoch-(32): [5500/10000]	Time 0.284 (0.138)	Calc 0.267 (0.078)	Data 0.001 (0.047)	Loss 0.468 (0.696)	Acc@1 80.000 (73.440)
2023-10-08 21:19:51,904 [INFO] core.trainer: Epoch-(32): [5600/10000]	Time 0.040 (0.138)	Calc 0.032 (0.078)	Data 0.001 (0.047)	Loss 0.614 (0.696)	Acc@1 80.000 (73.411)
2023-10-08 21:19:58,040 [INFO] core.trainer: Epoch-(32): [5700/10000]	Time 0.130 (0.138)	Calc 0.112 (0.079)	Data 0.001 (0.046)	Loss 0.372 (0.697)	Acc@1 76.667 (73.390)
2023-10-08 21:20:05,392 [INFO] core.trainer: Epoch-(32): [5800/10000]	Time 0.400 (0.138)	Calc 0.393 (0.079)	Data 0.001 (0.046)	Loss 0.722 (0.696)	Acc@1 64.000 (73.397)
2023-10-08 21:20:13,069 [INFO] core.trainer: Epoch-(32): [5900/10000]	Time 0.244 (0.138)	Calc 0.016 (0.079)	Data 0.221 (0.047)	Loss 0.594 (0.696)	Acc@1 76.000 (73.395)
2023-10-08 21:20:19,633 [INFO] core.trainer: Epoch-(32): [6000/10000]	Time 0.502 (0.138)	Calc 0.015 (0.078)	Data 0.480 (0.047)	Loss 0.831 (0.697)	Acc@1 70.667 (73.403)
2023-10-08 21:20:26,311 [INFO] core.trainer: Epoch-(32): [6100/10000]	Time 0.061 (0.138)	Calc 0.054 (0.077)	Data 0.001 (0.048)	Loss 0.566 (0.697)	Acc@1 74.667 (73.398)
2023-10-08 21:20:32,813 [INFO] core.trainer: Epoch-(32): [6200/10000]	Time 0.068 (0.138)	Calc 0.049 (0.077)	Data 0.001 (0.048)	Loss 0.904 (0.697)	Acc@1 76.667 (73.400)
2023-10-08 21:20:39,982 [INFO] core.trainer: Epoch-(32): [6300/10000]	Time 0.025 (0.138)	Calc 0.017 (0.077)	Data 0.001 (0.048)	Loss 0.518 (0.697)	Acc@1 80.000 (73.405)
2023-10-08 21:20:47,562 [INFO] core.trainer: Epoch-(32): [6400/10000]	Time 0.258 (0.138)	Calc 0.237 (0.076)	Data 0.001 (0.049)	Loss 0.349 (0.697)	Acc@1 85.333 (73.396)
2023-10-08 21:20:54,336 [INFO] core.trainer: Epoch-(32): [6500/10000]	Time 0.038 (0.138)	Calc 0.028 (0.076)	Data 0.000 (0.049)	Loss 0.624 (0.697)	Acc@1 70.667 (73.371)
2023-10-08 21:21:01,608 [INFO] core.trainer: Epoch-(32): [6600/10000]	Time 0.255 (0.138)	Calc 0.152 (0.077)	Data 0.085 (0.049)	Loss 0.556 (0.697)	Acc@1 71.333 (73.401)
2023-10-08 21:21:08,155 [INFO] core.trainer: Epoch-(32): [6700/10000]	Time 0.043 (0.138)	Calc 0.036 (0.077)	Data 0.001 (0.048)	Loss 0.846 (0.697)	Acc@1 64.667 (73.396)
2023-10-08 21:21:15,639 [INFO] core.trainer: Epoch-(32): [6800/10000]	Time 0.107 (0.138)	Calc 0.092 (0.078)	Data 0.001 (0.048)	Loss 0.620 (0.696)	Acc@1 76.667 (73.399)
2023-10-08 21:21:22,745 [INFO] core.trainer: Epoch-(32): [6900/10000]	Time 0.161 (0.138)	Calc 0.060 (0.077)	Data 0.095 (0.048)	Loss 0.763 (0.696)	Acc@1 72.667 (73.395)
2023-10-08 21:21:29,084 [INFO] core.trainer: Epoch-(32): [7000/10000]	Time 0.039 (0.138)	Calc 0.024 (0.077)	Data 0.008 (0.048)	Loss 0.640 (0.696)	Acc@1 68.000 (73.391)
2023-10-08 21:21:35,894 [INFO] core.trainer: Epoch-(32): [7100/10000]	Time 0.050 (0.138)	Calc 0.044 (0.077)	Data 0.001 (0.048)	Loss 0.890 (0.696)	Acc@1 63.333 (73.380)
2023-10-08 21:21:43,629 [INFO] core.trainer: Epoch-(32): [7200/10000]	Time 0.038 (0.138)	Calc 0.032 (0.076)	Data 0.001 (0.049)	Loss 1.040 (0.696)	Acc@1 68.000 (73.394)
2023-10-08 21:21:50,576 [INFO] core.trainer: Epoch-(32): [7300/10000]	Time 0.187 (0.138)	Calc 0.161 (0.077)	Data 0.001 (0.049)	Loss 0.590 (0.696)	Acc@1 80.667 (73.386)
2023-10-08 21:21:57,361 [INFO] core.trainer: Epoch-(32): [7400/10000]	Time 0.032 (0.138)	Calc 0.026 (0.077)	Data 0.002 (0.048)	Loss 0.516 (0.696)	Acc@1 82.000 (73.378)
2023-10-08 21:22:05,319 [INFO] core.trainer: Epoch-(32): [7500/10000]	Time 0.055 (0.138)	Calc 0.039 (0.077)	Data 0.001 (0.049)	Loss 0.370 (0.695)	Acc@1 84.000 (73.385)
